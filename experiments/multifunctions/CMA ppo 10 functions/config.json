{"agent.algorithm": "RayProximalPolicyOptimization", "agent.algorithm.render_env": false, "agent.algorithm.num_workers": 0, "agent.algorithm.batch_mode": "complete_episodes", "agent.algorithm.lr": 1e-05, "agent.algorithm.train_batch_size": 200, "agent.algorithm.vf_clip_param": 10, "agent.algorithm.model": {"fcnet_activation": "relu", "fcnet_hiddens": [50, 50]}, "env.env_class": "SchedulerPolicyMultiRayEnvironment", "env.env_config": {"solver_driver": "CMAdriver", "solver_driver_args": [[10, 10, 12, 0.5], [10, 10, 11, 0.5], [10, 10, 2, 0.5], [10, 10, 23, 0.5], [10, 10, 15, 0.5], [10, 10, 8, 0.5], [10, 10, 17, 0.5], [10, 10, 20, 0.5], [10, 10, 1, 0.5], [10, 10, 16, 0.5]], "maximize": false, "steps": 50, "state_metrics_names": ["DifferenceOfBest", "SolverStateHistory"], "state_metrics_config": [[40, false, 1, true, true], [{"step_size": {"max": 3, "min": 0}}, 40]], "reward_metric": "DeltaBest", "reward_metric_config": [false, true, true], "memes_no": 1, "action_space_config": {"step_size": {"max": 3, "min": 1e-05}}}}