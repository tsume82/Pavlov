{"agent.algorithm": "RayProximalPolicyOptimization", "agent.algorithm.render_env": false, "agent.algorithm.num_workers": 0, "agent.algorithm.batch_mode": "complete_episodes", "agent.algorithm.lr": 5e-05, "agent.algorithm.train_batch_size": 200, "agent.algorithm.optimizer": "Adam", "agent.algorithm.vf_clip_param": 10, "agent.algorithm.model": {"fcnet_activation": "relu", "fcnet_hiddens": [50, 50]}, "env.env_class": "SchedulerPolicyRayEnvironment", "env.env_config": {"solver_driver": "DEdriver", "solver_driver_args": [5, 10, 19, "best1bin", "uniform"], "maximize": false, "steps": 50, "state_metrics_names": ["DifferenceOfBest", "SolverStateHistory"], "state_metrics_config": [[40, false, 1, true, false], [{"F_min": {"max": [2], "min": [0]}, "F_max": {"max": [2], "min": [0]}, "CR_min": {"max": [1], "min": [0]}, "CR_max": {"max": [1], "min": [0]}}, 40]], "reward_metric": "DeltaBest", "reward_metric_config": [false, true, true], "memes_no": 1, "action_space_config": {"F_min": {"max": 2, "min": 0}, "F_max": {"max": 2, "min": 0}, "CR_min": {"max": 1, "min": 0}, "CR_max": {"max": 1, "min": 0}}}}